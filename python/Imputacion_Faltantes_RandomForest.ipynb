{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/61dPOu052P1HXmC9htH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenryZumaeta/MISCELANEAS/blob/Zeta/PYTHON/Imputacion_Faltantes_RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmgdmfsQmsUo"
      },
      "outputs": [],
      "source": [
        "# Imputación por Random Forest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "\n",
        "# Separar las columnas numéricas y categóricas\n",
        "num_cols = df_combined.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = df_combined.select_dtypes(include=[object]).columns\n",
        "\n",
        "# Imputación para variables numéricas usando RandomForestRegressor\n",
        "imputer_num = IterativeImputer(estimator=RandomForestRegressor(), max_iter=10, random_state=0)\n",
        "df_combined[num_cols] = imputer_num.fit_transform(df_combined[num_cols])\n",
        "\n",
        "# Imputación para variables categóricas usando RandomForestClassifier\n",
        "for col in cat_cols:\n",
        "    df_combined[col] = df_combined[col].astype('category').cat.codes  # Convertir a códigos numéricos temporales para imputar\n",
        "    imputer_cat = IterativeImputer(estimator=RandomForestClassifier(), max_iter=10, random_state=0)\n",
        "    df_combined[col] = imputer_cat.fit_transform(df_combined[[col]])\n",
        "    df_combined[col] = pd.Categorical.from_codes(df_combined[col].astype(int), categories=df_combined[col].astype('category').cat.categories)  # Reconstruir categorías originales\n",
        "\n",
        "# Guardar el DataFrame imputado en un archivo CSV\n",
        "#df_combined.to_csv('raleo_base_clus_clusteres_imputed.csv', index=False)\n",
        "\n",
        "print(\"DataFrame imputado:\\n\", df_combined.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ieAmNnYkFLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "def missForest(xmis, max_iter=10, n_trees=100, variablewise=False, decreasing=False,\n",
        "               verbose=False, mtry=None, replace=True, classwt=None, cutoff=None,\n",
        "               strata=None, sampsize=None, nodesize=None, maxnodes=None, xtrue=None,\n",
        "               parallelize=\"no\"):\n",
        "\n",
        "    def initialize(xmis):\n",
        "        n, p = xmis.shape\n",
        "        ximp = xmis.copy()\n",
        "        var_type = []\n",
        "        for col in xmis.columns:\n",
        "            if pd.api.types.is_numeric_dtype(xmis[col]):\n",
        "                var_type.append(\"numeric\")\n",
        "                ximp[col].fillna(ximp[col].mean(), inplace=True)\n",
        "            elif pd.api.types.is_categorical_dtype(xmis[col]):\n",
        "                var_type.append(\"factor\")\n",
        "                most_frequent = ximp[col].mode()[0]\n",
        "                ximp[col].fillna(most_frequent, inplace=True)\n",
        "            else:\n",
        "                raise ValueError(f\"Column {col} must be factor or numeric\")\n",
        "        return ximp, var_type\n",
        "\n",
        "    def stop_criterion(var_type, conv_new, conv_old, iter, max_iter):\n",
        "        if len(set(var_type)) == 1:\n",
        "            return (conv_new < conv_old) & (iter < max_iter)\n",
        "        else:\n",
        "            return ((conv_new[0] < conv_old[0]) or (conv_new[1] < conv_old[1])) & (iter < max_iter)\n",
        "\n",
        "    n, p = xmis.shape\n",
        "    if mtry is None:\n",
        "        mtry = int(np.floor(np.sqrt(p)))\n",
        "\n",
        "    ximp, var_type = initialize(xmis)\n",
        "\n",
        "    if any(xmis.isnull().all()):\n",
        "        indCmis = xmis.columns[xmis.isnull().all()]\n",
        "        xmis = xmis.drop(columns=indCmis)\n",
        "        ximp = ximp.drop(columns=indCmis)\n",
        "        p = xmis.shape[1]\n",
        "        if verbose:\n",
        "            print(f\"  removed variable(s) {indCmis} due to the missingness of all entries\")\n",
        "\n",
        "    NAloc = xmis.isnull()\n",
        "    noNAvar = NAloc.sum()\n",
        "    sort_j = noNAvar.argsort()\n",
        "    if decreasing:\n",
        "        sort_j = sort_j[::-1]\n",
        "    sort_noNAvar = noNAvar[sort_j]\n",
        "    nzsort_j = sort_j[sort_noNAvar > 0]\n",
        "\n",
        "    Ximp = []\n",
        "    iter = 0\n",
        "    k = len(set(var_type))\n",
        "    conv_new = np.zeros(k)\n",
        "    conv_old = np.full(k, np.inf)\n",
        "    OOBerror = np.zeros(p)\n",
        "    names_OOBerror = np.array(var_type)\n",
        "\n",
        "    if k == 1:\n",
        "        convergence = np.array([])\n",
        "        OOBerr = np.zeros(1)\n",
        "    else:\n",
        "        convergence = np.full((max_iter, 2), np.nan)\n",
        "        OOBerr = np.zeros(2)\n",
        "\n",
        "    while stop_criterion(var_type, conv_new, conv_old, iter, max_iter):\n",
        "        if iter != 0:\n",
        "            conv_old = conv_new.copy()\n",
        "            OOBerrOld = OOBerr.copy()\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  missForest iteration {iter + 1} in progress...\")\n",
        "\n",
        "        ximp_old = ximp.copy()\n",
        "\n",
        "        for s in range(p):\n",
        "            var_ind = sort_j[s]\n",
        "            if noNAvar[var_ind] != 0:\n",
        "                obsi = ~NAloc.iloc[:, var_ind]\n",
        "                misi = NAloc.iloc[:, var_ind]\n",
        "                obsY = ximp.loc[obsi, xmis.columns[var_ind]]\n",
        "                obsX = ximp.loc[obsi, xmis.columns != xmis.columns[var_ind]]\n",
        "                misX = ximp.loc[misi, xmis.columns != xmis.columns[var_ind]]\n",
        "                typeY = var_type[var_ind]\n",
        "\n",
        "                if typeY == \"numeric\":\n",
        "                    model = RandomForestRegressor(n_estimators=n_trees, max_features=mtry, bootstrap=replace)\n",
        "                    model.fit(obsX, obsY)\n",
        "                    misY = model.predict(misX)\n",
        "                    OOBerror[var_ind] = np.mean((model.predict(obsX) - obsY) ** 2)\n",
        "                else:\n",
        "                    model = RandomForestClassifier(n_estimators=n_trees, max_features=mtry, bootstrap=replace)\n",
        "                    model.fit(obsX, obsY)\n",
        "                    misY = model.predict(misX)\n",
        "                    OOBerror[var_ind] = 1 - np.mean(model.predict(obsX) == obsY)\n",
        "\n",
        "                ximp.loc[misi, xmis.columns[var_ind]] = misY\n",
        "\n",
        "        iter += 1\n",
        "        Ximp.append(ximp.copy())\n",
        "\n",
        "        for t_type in set(var_type):\n",
        "            t_ind = [i for i, x in enumerate(var_type) if x == t_type]\n",
        "            if t_type == \"numeric\":\n",
        "                conv_new[0] = np.sum((ximp.iloc[:, t_ind] - ximp_old.iloc[:, t_ind]) ** 2) / np.sum(ximp.iloc[:, t_ind] ** 2)\n",
        "            else:\n",
        "                conv_new[1] = np.sum(ximp.iloc[:, t_ind] != ximp_old.iloc[:, t_ind]) / (n * np.sum(np.array(var_type) == \"factor\"))\n",
        "\n",
        "        if not variablewise:\n",
        "            NRMSE = np.sqrt(np.mean(OOBerror[np.array(var_type) == \"numeric\"]) / np.var(xmis.to_numpy()[:, np.array(var_type) == \"numeric\"], ddof=1))\n",
        "            PFC = np.mean(OOBerror[np.array(var_type) == \"factor\"])\n",
        "            if k == 1:\n",
        "                OOBerr[0] = NRMSE if \"numeric\" in var_type else PFC\n",
        "            else:\n",
        "                OOBerr = np.array([NRMSE, PFC])\n",
        "        else:\n",
        "            OOBerr = OOBerror\n",
        "            names_OOBerror[np.array(var_type) == \"numeric\"] = \"MSE\"\n",
        "            names_OOBerror[np.array(var_type) == \"factor\"] = \"PFC\"\n",
        "\n",
        "        if xtrue is not None:\n",
        "            err = mix_error(ximp, xmis, xtrue)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    error(s): {err}\" if xtrue is not None else \"\")\n",
        "            print(f\"    estimated error(s): {OOBerr}\")\n",
        "            print(f\"    difference(s): {conv_new}\")\n",
        "\n",
        "    if iter == max_iter:\n",
        "        result = {\"ximp\": Ximp[-1], \"OOBerror\": OOBerr}\n",
        "    else:\n",
        "        result = {\"ximp\": Ximp[-2], \"OOBerror\": OOBerrOld, \"error\": err} if xtrue is not None else {\"ximp\": Ximp[-2], \"OOBerror\": OOBerrOld}\n",
        "\n",
        "    return result\n",
        "\n",
        "def mix_error(ximp, xmis, xtrue):\n",
        "    n, p = xtrue.shape\n",
        "    error = np.zeros(p)\n",
        "    for j in range(p):\n",
        "        if pd.api.types.is_numeric_dtype(xtrue.iloc[:, j]):\n",
        "            error[j] = np.sqrt(np.sum((ximp.iloc[:, j] - xtrue.iloc[:, j]) ** 2) / np.sum((xmis.iloc[:, j] - xtrue.iloc[:, j]) ** 2))\n",
        "        else:\n",
        "            error[j] = np.sum(ximp.iloc[:, j] != xtrue.iloc[:, j]) / np.sum(xmis.iloc[:, j] != xtrue.iloc[:, j])\n",
        "    return error\n"
      ],
      "metadata": {
        "id": "UsFu9R_OpFfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame de ejemplo con valores faltantes\n",
        "data = {\n",
        "    'A': [1, 2, np.nan, 4],\n",
        "    'B': [np.nan, 1, 3, 4],\n",
        "    'C': [4, 2, np.nan, 3]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convertir la columna categórica a tipo 'category'\n",
        "df['C'] = df['C'].astype('category')\n",
        "\n",
        "# Ejecutar la función missForest\n",
        "result = missForest(df, max_iter=10, n_trees=100, verbose=True)\n",
        "\n",
        "# Obtener los datos imputados\n",
        "imputed_data = result['ximp']\n",
        "\n",
        "# Mostrar los datos imputados\n",
        "print(imputed_data)"
      ],
      "metadata": {
        "id": "U79H1alNpUsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install missingpy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from missingpy import MissForest\n",
        "\n",
        "# Crear un DataFrame de ejemplo con valores faltantes\n",
        "data = {\n",
        "    'A': [1, 2, np.nan, 4],\n",
        "    'B': [np.nan, 1, 3, 4],\n",
        "    'C': ['a', 'b', np.nan, 'd']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convertir la columna categórica a tipo 'category'\n",
        "df['C'] = df['C'].astype('category')\n",
        "\n",
        "# Inicializar el imputador MissForest\n",
        "imputer = MissForest(verbose=True)\n",
        "\n",
        "# Realizar la imputación\n",
        "imputed_data = imputer.fit_transform(df)\n",
        "\n",
        "# Convertir el resultado a un DataFrame\n",
        "imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\n",
        "\n",
        "# Mostrar los datos imputados\n",
        "print(imputed_df)\n"
      ],
      "metadata": {
        "id": "r2ItaVCwkaVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install MissForest\n",
        "from missforest.missforest import MissForest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "\n",
        "df = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\n",
        "\n",
        "np.random.seed(0)\n",
        "clf = RandomForestClassifier(n_jobs=-1)\n",
        "rgr = RandomForestRegressor(n_jobs=-1)\n",
        "\n",
        "mf = MissForest(clf, rgr)\n",
        "df_imputed = mf.fit_transform(df)"
      ],
      "metadata": {
        "id": "RbIQiWB6kgEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from missingpy import MissForest\n",
        "from sklearn.neighbors import DistanceMetric\n",
        "nan = float(\"NaN\")\n",
        "np.random.seed(0)\n",
        "X = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\n",
        "imputer = MissForest()\n",
        "imputer.fit_transform(X)"
      ],
      "metadata": {
        "id": "-fqJvTuckju8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from missingpy import MissForest\n",
        "\n",
        "# Crear un DataFrame con valores faltantes\n",
        "np.random.seed(0)\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, np.nan, 4, 5],\n",
        "    'B': [np.nan, 2, 3, 4, 5],\n",
        "    'C': [1, np.nan, 3, 4, 5]\n",
        "})\n",
        "\n",
        "# Imprimir el DataFrame original con valores faltantes\n",
        "print(\"DataFrame original con valores faltantes:\")\n",
        "print(df)\n",
        "\n",
        "# Crear una instancia del imputador MissForest\n",
        "imputer = MissForest()\n",
        "\n",
        "# Imputar los valores faltantes\n",
        "df_imputed = imputer.fit_transform(df)\n",
        "\n",
        "# Convertir el resultado a un DataFrame de Pandas\n",
        "df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n",
        "\n",
        "# Imprimir el DataFrame imputado\n",
        "print(\"\\nDataFrame con valores imputados:\")\n",
        "print(df_imputed)\n"
      ],
      "metadata": {
        "id": "fk0FbUZSkoEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, SimpleImputer\n",
        "from sklearn.linear_model import BayesianRidge, Lasso\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Mapear los métodos a los imputadores correspondientes\n",
        "method_map = {\n",
        "    'mean': SimpleImputer(strategy='mean'),\n",
        "    'norm': IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=0),\n",
        "    'norm.nob': IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=0),  # Ajustado\n",
        "    'norm.boot': IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=0),  # Ajustado\n",
        "    'norm.predict': IterativeImputer(estimator=LinearRegression(), max_iter=10, random_state=0),  # Ajustado\n",
        "    'lasso.norm': IterativeImputer(estimator=Lasso(), max_iter=10, random_state=0),  # Sustituido\n",
        "    'lasso.select.norm': IterativeImputer(estimator=Lasso(), max_iter=10, random_state=0),  # Sustituido\n",
        "    'quadratic': IterativeImputer(estimator=LinearRegression(), max_iter=10, random_state=0),  # Sustituido\n",
        "    'ri': IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=0),\n",
        "    'logreg': IterativeImputer(estimator=LogisticRegression(), max_iter=10, random_state=0),\n",
        "    'logreg.boot': IterativeImputer(estimator=LogisticRegression(), max_iter=10, random_state=0),  # Ajustado\n",
        "    'lasso.logreg': IterativeImputer(estimator=LogisticRegression(), max_iter=10, random_state=0),  # Sustituido\n",
        "    'lasso.select.logreg': IterativeImputer(estimator=LogisticRegression(), max_iter=10, random_state=0),  # Sustituido\n",
        "    'rf': IterativeImputer(estimator=RandomForestRegressor(), max_iter=10, random_state=0),\n",
        "    'cart': IterativeImputer(estimator=DecisionTreeRegressor(), max_iter=10, random_state=0),\n",
        "    # Otros métodos pueden ser agregados aquí\n",
        "}\n",
        "\n",
        "def imputar_datos_numericos(data, method='mean', m=5, max_iter=10, random_state=None):\n",
        "    \"\"\"\n",
        "    Imputación de datos numéricos utilizando diferentes métodos.\n",
        "\n",
        "    Args:\n",
        "    data (pd.DataFrame): DataFrame con los datos a imputar.\n",
        "    method (str): Método de imputación a utilizar. Valores posibles:\n",
        "                  'mean', 'norm', 'logreg', 'rf', 'cart', etc.\n",
        "    m (int): Número de conjuntos de imputación a generar.\n",
        "    max_iter (int): Número máximo de iteraciones para cada imputación.\n",
        "    random_state (int): Semilla para asegurar reproducibilidad.\n",
        "\n",
        "    Returns:\n",
        "    list: Una lista de DataFrames imputados.\n",
        "    \"\"\"\n",
        "    if method not in method_map:\n",
        "        raise ValueError(f\"Método de imputación {method} no reconocido. \"\n",
        "                         f\"Elija entre {list(method_map.keys())}\")\n",
        "\n",
        "    imputer = method_map[method]\n",
        "\n",
        "    imputaciones = []\n",
        "\n",
        "    for _ in range(m):\n",
        "        imputacion = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "        imputaciones.append(imputacion)\n",
        "\n",
        "    return imputaciones\n",
        "\n",
        "# Ejemplo de uso\n",
        "if __name__ == \"__main__\":\n",
        "    # Crear un DataFrame de ejemplo con datos faltantes\n",
        "    np.random.seed(0)\n",
        "    df = pd.DataFrame({\n",
        "        'A': [1, 2, np.nan, 4, 5],\n",
        "        'B': [5, np.nan, np.nan, 8, 10],\n",
        "        'C': [np.nan, 1, 1, 2, np.nan]\n",
        "    })\n",
        "\n",
        "    # Mostrar el DataFrame original\n",
        "    print(\"DataFrame original:\")\n",
        "    print(df)\n",
        "\n",
        "    # Imputar los datos numéricos faltantes usando el método 'mean'\n",
        "    imputaciones = imputar_datos_numericos(df, method='mean', m=5, max_iter=10, random_state=0)\n",
        "\n",
        "    # Mostrar los DataFrames imputados\n",
        "    for i, imputacion in enumerate(imputaciones):\n",
        "        print(f\"\\nDataFrame imputado {i+1} (método 'mean'):\")\n",
        "        print(imputacion)\n",
        "\n",
        "    # Imputar los datos numéricos faltantes usando el método 'norm'\n",
        "    imputaciones = imputar_datos_numericos(df, method='norm', m=5, max_iter=10, random_state=0)\n",
        "\n",
        "    # Mostrar los DataFrames imputados\n",
        "    for i, imputacion in enumerate(imputaciones):\n",
        "        print(f\"\\nDataFrame imputado {i+1} (método 'norm'):\")\n",
        "        print(imputacion)"
      ],
      "metadata": {
        "id": "qvSVrqcpksAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "def missForest(xmis, maxiter=10, ntree=100, variablewise=False,\n",
        "               decreasing=False, verbose=False, mtry=None,\n",
        "               replace=True, classwt=None, cutoff=None, strata=None,\n",
        "               sampsize=None, nodesize=None, maxnodes=None, xtrue=None,\n",
        "               parallelize='no'):\n",
        "\n",
        "    n, p = xmis.shape\n",
        "    if mtry is None:\n",
        "        mtry = int(np.sqrt(p))\n",
        "\n",
        "    if classwt is not None:\n",
        "        assert len(classwt) == p and isinstance(classwt, list), \"classwt must be a list of length p\"\n",
        "    if cutoff is not None:\n",
        "        assert len(cutoff) == p and isinstance(cutoff, list), \"cutoff must be a list of length p\"\n",
        "    if strata is not None:\n",
        "        assert len(strata) == p and isinstance(strata, list), \"strata must be a list of length p\"\n",
        "    if nodesize is not None:\n",
        "        assert len(nodesize) == 2, \"nodesize must be of length 2\"\n",
        "\n",
        "    # Remove columns with all missing values\n",
        "    na_counts = xmis.isnull().sum()\n",
        "    all_na_cols = na_counts[na_counts == n].index\n",
        "    if len(all_na_cols) > 0:\n",
        "        xmis = xmis.drop(columns=all_na_cols)\n",
        "        p = xmis.shape[1]\n",
        "        if verbose:\n",
        "            print(f\"Removed columns {all_na_cols.tolist()} due to all values being missing.\")\n",
        "\n",
        "    parallelize = parallelize.lower()\n",
        "    if parallelize not in ['no', 'variables', 'forests']:\n",
        "        raise ValueError(\"parallelize must be one of 'no', 'variables', or 'forests'\")\n",
        "\n",
        "    if parallelize != 'no' and len(pd.unique(xmis.dtypes)) > 1:\n",
        "        raise ValueError(\"Parallelization is not supported with mixed data types\")\n",
        "\n",
        "    # Initial imputation\n",
        "    ximp = xmis.copy()\n",
        "    varType = ximp.dtypes.apply(lambda dt: 'numeric' if np.issubdtype(dt, np.number) else 'factor')\n",
        "\n",
        "    for col in ximp.columns:\n",
        "        if varType[col] == 'numeric':\n",
        "            ximp[col].fillna(ximp[col].mean(), inplace=True)\n",
        "        else:\n",
        "            most_common = ximp[col].mode()[0]\n",
        "            ximp[col].fillna(most_common, inplace=True)\n",
        "\n",
        "    # Convergence criteria\n",
        "    convNew = np.zeros(2)\n",
        "    convOld = np.inf * np.ones(2)\n",
        "    OOBerror = np.zeros(p)\n",
        "\n",
        "    iter = 0\n",
        "    stopCriterion = lambda varType, convNew, convOld, iter, maxiter: \\\n",
        "                    (convNew[0] < convOld[0] or convNew[1] < convOld[1]) and iter < maxiter\n",
        "\n",
        "    while stopCriterion(varType, convNew, convOld, iter, maxiter):\n",
        "        if iter != 0:\n",
        "            convOld = convNew\n",
        "            OOBerrOld = OOBerror\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"missForest iteration {iter + 1} in progress...\")\n",
        "\n",
        "        ximp_old = ximp.copy()\n",
        "        na_loc = xmis.isnull()\n",
        "\n",
        "        # Order variables by number of missing values\n",
        "        noNAvar = na_loc.sum()\n",
        "        sort_j = noNAvar.sort_values(ascending=not decreasing).index\n",
        "        nzsort_j = sort_j[noNAvar[sort_j] > 0]\n",
        "\n",
        "        if parallelize == 'variables':\n",
        "            results = Parallel(n_jobs=-1)(delayed(impute_column)(ximp, na_loc, varType, i, mtry, ntree, replace, nodesize, maxnodes) for i in nzsort_j)\n",
        "            for res in results:\n",
        "                ximp.loc[na_loc[res['varInd']], res['varInd']] = res['misY']\n",
        "                OOBerror[res['varInd']] = res['oerr']\n",
        "        else:\n",
        "            for varInd in nzsort_j:\n",
        "                if na_loc[varInd].sum() > 0:\n",
        "                    ximp, OOBerror[varInd] = impute_column(ximp, na_loc, varType, varInd, mtry, ntree, replace, nodesize, maxnodes)\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        # Convergence check\n",
        "        numeric_indices = np.where(varType == 'numeric')[0]\n",
        "        factor_indices = np.where(varType == 'factor')[0]\n",
        "\n",
        "        convNew[0] = np.sum((ximp.iloc[:, numeric_indices] - ximp_old.iloc[:, numeric_indices])**2) / np.sum(ximp.iloc[:, numeric_indices]**2)\n",
        "        convNew[1] = np.sum((ximp.iloc[:, factor_indices] != ximp_old.iloc[:, factor_indices])) / (n * len(factor_indices))\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Convergence: Numeric = {convNew[0]}, Factor = {convNew[1]}\")\n",
        "\n",
        "    if iter == maxiter:\n",
        "        ximp_final = ximp\n",
        "    else:\n",
        "        ximp_final = ximp_old\n",
        "\n",
        "    return ximp_final, OOBerror\n",
        "\n",
        "def impute_column(ximp, na_loc, varType, varInd, mtry, ntree, replace, nodesize, maxnodes):\n",
        "    obsi = ~na_loc[varInd]\n",
        "    misi = na_loc[varInd]\n",
        "    obsY = ximp.loc[obsi, varInd]\n",
        "    obsX = ximp.loc[obsi, ximp.columns != varInd]\n",
        "    misX = ximp.loc[misi, ximp.columns != varInd]\n",
        "\n",
        "    if varType[varInd] == 'numeric':\n",
        "        model = RandomForestRegressor(n_estimators=ntree, max_features=mtry, bootstrap=replace, min_samples_leaf=nodesize[0] if nodesize else 1, max_leaf_nodes=maxnodes)\n",
        "        model.fit(obsX, obsY)\n",
        "        misY = model.predict(misX)\n",
        "        oerr = mean_squared_error(obsY, model.predict(obsX))\n",
        "    else:\n",
        "        le = LabelEncoder()\n",
        "        obsY_enc = le.fit_transform(obsY)\n",
        "        model = RandomForestClassifier(n_estimators=ntree, max_features=mtry, bootstrap=replace, min_samples_leaf=nodesize[1] if nodesize else 5, max_leaf_nodes=maxnodes)\n",
        "        model.fit(obsX, obsY_enc)\n",
        "        misY = le.inverse_transform(model.predict(misX))\n",
        "        oerr = 1 - accuracy_score(obsY_enc, model.predict(obsX))\n",
        "\n",
        "    return {'varInd': varInd, 'misY': misY, 'oerr': oerr}\n",
        "\n",
        "# Ejemplo de uso\n",
        "data = pd.DataFrame({\n",
        "    'A': [1, 2, np.nan, 4, 5],\n",
        "    'B': ['a', 'b', 'c', np.nan, 'e'],\n",
        "    'C': [np.nan, 1.5, 2.5, 3.5, np.nan]\n",
        "})\n",
        "\n",
        "imputed_data, oob_error = missForest(data, verbose=True)\n",
        "print(imputed_data)\n"
      ],
      "metadata": {
        "id": "c8WDcvX_kxVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "def missForest(xmis, maxiter=10, ntree=100, variablewise=False,\n",
        "               decreasing=False, verbose=False, mtry=None,\n",
        "               replace=True, classwt=None, cutoff=None, strata=None,\n",
        "               sampsize=None, nodesize=None, maxnodes=None, xtrue=None,\n",
        "               parallelize='no'):\n",
        "\n",
        "    n, p = xmis.shape\n",
        "    if mtry is None:\n",
        "        mtry = int(np.sqrt(p))\n",
        "\n",
        "    if classwt is not None:\n",
        "        assert len(classwt) == p and isinstance(classwt, list), \"classwt must be a list of length p\"\n",
        "    if cutoff is not None:\n",
        "        assert len(cutoff) == p and isinstance(cutoff, list), \"cutoff must be a list of length p\"\n",
        "    if strata is not None:\n",
        "        assert len(strata) == p and isinstance(strata, list), \"strata must be a list of length p\"\n",
        "    if nodesize is not None:\n",
        "        assert len(nodesize) == 2, \"nodesize must be of length 2\"\n",
        "\n",
        "    # Remove columns with all missing values\n",
        "    na_counts = xmis.isnull().sum()\n",
        "    all_na_cols = na_counts[na_counts == n].index\n",
        "    if len(all_na_cols) > 0:\n",
        "        xmis = xmis.drop(columns=all_na_cols)\n",
        "        p = xmis.shape[1]\n",
        "        if verbose:\n",
        "            print(f\"Removed columns {all_na_cols.tolist()} due to all values being missing.\")\n",
        "\n",
        "    parallelize = parallelize.lower()\n",
        "    if parallelize not in ['no', 'variables', 'forests']:\n",
        "        raise ValueError(\"parallelize must be one of 'no', 'variables', or 'forests'\")\n",
        "\n",
        "    if parallelize != 'no' and len(pd.unique(xmis.dtypes)) > 1:\n",
        "        raise ValueError(\"Parallelization is not supported with mixed data types\")\n",
        "\n",
        "    # Initial imputation\n",
        "    ximp = xmis.copy()\n",
        "    varType = ximp.dtypes.apply(lambda dt: 'numeric' if np.issubdtype(dt, np.number) else 'factor')\n",
        "\n",
        "    label_encoders = {}\n",
        "    for col in ximp.columns:\n",
        "        if varType[col] == 'numeric':\n",
        "            ximp[col].fillna(ximp[col].mean(), inplace=True)\n",
        "        else:\n",
        "            le = LabelEncoder()\n",
        "            ximp[col] = le.fit_transform(ximp[col].astype(str))\n",
        "            ximp[col].fillna(le.transform([ximp[col].mode()[0]])[0], inplace=True)\n",
        "            label_encoders[col] = le\n",
        "\n",
        "    # Convergence criteria\n",
        "    convNew = np.zeros(2)\n",
        "    convOld = np.inf * np.ones(2)\n",
        "    OOBerror = np.zeros(p)\n",
        "\n",
        "    iter = 0\n",
        "    stopCriterion = lambda varType, convNew, convOld, iter, maxiter: \\\n",
        "                    (convNew[0] < convOld[0] or convNew[1] < convOld[1]) and iter < maxiter\n",
        "\n",
        "    while stopCriterion(varType, convNew, convOld, iter, maxiter):\n",
        "        if iter != 0:\n",
        "            convOld = convNew\n",
        "            OOBerrOld = OOBerror\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"missForest iteration {iter + 1} in progress...\")\n",
        "\n",
        "        ximp_old = ximp.copy()\n",
        "        na_loc = xmis.isnull()\n",
        "\n",
        "        # Order variables by number of missing values\n",
        "        noNAvar = na_loc.sum()\n",
        "        sort_j = noNAvar.sort_values(ascending=not decreasing).index\n",
        "        nzsort_j = sort_j[noNAvar[sort_j] > 0]\n",
        "\n",
        "        if parallelize == 'variables':\n",
        "            results = Parallel(n_jobs=-1)(delayed(impute_column)(ximp, na_loc, varType, i, mtry, ntree, replace, nodesize, maxnodes, label_encoders) for i in nzsort_j)\n",
        "            for res in results:\n",
        "                ximp.loc[na_loc[res['varInd']], res['varInd']] = res['misY']\n",
        "                OOBerror[res['varInd']] = res['oerr']\n",
        "        else:\n",
        "            for varInd in nzsort_j:\n",
        "                if na_loc[varInd].sum() > 0:\n",
        "                    ximp, OOBerror[varInd] = impute_column(ximp, na_loc, varType, varInd, mtry, ntree, replace, nodesize, maxnodes, label_encoders)\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        # Convergence check\n",
        "        numeric_indices = np.where(varType == 'numeric')[0]\n",
        "        factor_indices = np.where(varType == 'factor')[0]\n",
        "\n",
        "        convNew[0] = np.sum((ximp.iloc[:, numeric_indices] - ximp_old.iloc[:, numeric_indices])**2) / np.sum(ximp.iloc[:, numeric_indices]**2)\n",
        "        convNew[1] = np.sum((ximp.iloc[:, factor_indices] != ximp_old.iloc[:, factor_indices])) / (n * len(factor_indices))\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Convergence: Numeric = {convNew[0]}, Factor = {convNew[1]}\")\n",
        "\n",
        "    if iter == maxiter:\n",
        "        ximp_final = ximp\n",
        "    else:\n",
        "        ximp_final = ximp_old\n",
        "\n",
        "    # Decode factor variables\n",
        "    for col in label_encoders:\n",
        "        ximp_final[col] = label_encoders[col].inverse_transform(ximp_final[col].astype(int))\n",
        "\n",
        "    return ximp_final, OOBerror\n",
        "\n",
        "def impute_column(ximp, na_loc, varType, varInd, mtry, ntree, replace, nodesize, maxnodes, label_encoders):\n",
        "    obsi = ~na_loc[varInd]\n",
        "    misi = na_loc[varInd]\n",
        "    obsY = ximp.loc[obsi, varInd]\n",
        "    obsX = ximp.loc[obsi, ximp.columns != varInd]\n",
        "    misX = ximp.loc[misi, ximp.columns != varInd]\n",
        "\n",
        "    if varType[varInd] == 'numeric':\n",
        "        model = RandomForestRegressor(n_estimators=ntree, max_features=mtry, bootstrap=replace, min_samples_leaf=nodesize[0] if nodesize else 1, max_leaf_nodes=maxnodes)\n",
        "        model.fit(obsX, obsY)\n",
        "        misY = model.predict(misX)\n",
        "        oerr = mean_squared_error(obsY, model.predict(obsX))\n",
        "    else:\n",
        "        model = RandomForestClassifier(n_estimators=ntree, max_features=mtry, bootstrap=replace, min_samples_leaf=nodesize[1] if nodesize else 5, max_leaf_nodes=maxnodes)\n",
        "        model.fit(obsX, obsY)\n",
        "        misY = model.predict(misX)\n",
        "        oerr = 1 - accuracy_score(obsY, model.predict(obsX))\n",
        "\n",
        "    return {'varInd': varInd, 'misY': misY, 'oerr': oerr}\n",
        "\n",
        "# Ejemplo de uso\n",
        "data = pd.DataFrame({\n",
        "    'A': [1, 2, np.nan, 4, 5],\n",
        "    'B': ['a', 'b', 'c', np.nan, 'e'],\n",
        "    'C': [np.nan, 1.5, 2.5, 3.5, np.nan]\n",
        "})\n",
        "\n",
        "imputed_data, oob_error = missForest(data, verbose=True)\n",
        "print(imputed_data)\n"
      ],
      "metadata": {
        "id": "DBWgf8W5k19b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "def miss_forest(xmis, maxiter=10, ntree=100, variablewise=False,\n",
        "                decreasing=False, verbose=False, mtry=None,\n",
        "                replace=True, classwt=None, cutoff=None, strata=None,\n",
        "                sampsize=None, nodesize=None, maxnodes=None, xtrue=None,\n",
        "                parallelize='no'):\n",
        "    n, p = xmis.shape\n",
        "    if mtry is None:\n",
        "        mtry = int(np.floor(np.sqrt(p)))\n",
        "\n",
        "    ximp = xmis.copy()\n",
        "    varType = ['numeric' if pd.api.types.is_numeric_dtype(xmis.iloc[:, i]) else 'categorical'\n",
        "               for i in range(p)]\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Starting missForest imputation...\")\n",
        "\n",
        "    for iteration in range(maxiter):\n",
        "        if verbose:\n",
        "            print(f\"Iteration {iteration + 1}\")\n",
        "\n",
        "        for column in range(p):\n",
        "            if xmis.iloc[:, column].isna().all():\n",
        "                continue  # Skip columns with all values missing\n",
        "\n",
        "            y = ximp.iloc[:, column]\n",
        "            X = ximp.drop(ximp.columns[column], axis=1)\n",
        "            is_numeric = varType[column] == 'numeric'\n",
        "\n",
        "            # Prepare model based on type of variable\n",
        "            if is_numeric:\n",
        "                model = RandomForestRegressor(n_estimators=ntree, max_features=mtry, bootstrap=replace,\n",
        "                                              max_leaf_nodes=maxnodes, min_samples_leaf=nodesize)\n",
        "            else:\n",
        "                model = RandomForestClassifier(n_estimators=ntree, max_features=mtry, bootstrap=replace,\n",
        "                                               max_leaf_nodes=maxnodes, min_samples_leaf=nodesize)\n",
        "\n",
        "            not_na_indices = ~y.isna()\n",
        "            na_indices = y.isna()\n",
        "            if not_na_indices.any():\n",
        "                model.fit(X.loc[not_na_indices], y[not_na_indices])\n",
        "                predictions = model.predict(X.loc[na_indices])\n",
        "                ximp.loc[na_indices, ximp.columns[column]] = predictions\n",
        "\n",
        "        # Check for convergence (implementation needed as per specific criteria)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Imputation completed.\")\n",
        "\n",
        "    return ximp\n",
        "\n",
        "# Example usage\n",
        "# df = pd.read_csv('your_data.csv')  # Load your data into a DataFrame\n",
        "# imputed_data = miss_forest(df)\n",
        "\n",
        "# Example usage\n",
        "# Ejemplo de uso\n",
        "data = pd.DataFrame({\n",
        "    'A': [1, 2, np.nan, 4, 5],\n",
        "    'B': ['a', 'b', 'c', np.nan, 'e'],\n",
        "    'C': [np.nan, 1.5, 2.5, 3.5, np.nan]\n",
        "})\n",
        "\n",
        "imputed_data = miss_forest(data)\n"
      ],
      "metadata": {
        "id": "3nt0qc3Yk536"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}