{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeCT080gO22sO7+Qczjlru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenryZumaeta/MISCELANEAS/blob/Zeta/PYTHON/Asociacion_Numerico_Categorico_Correlacion_Incertidumbre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replicando el correlograma de la librería sweetviz"
      ],
      "metadata": {
        "id": "FGb1sorXq5p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "from matplotlib.cm import ScalarMappable\n",
        "from scipy.stats import chi2_contingency, entropy\n",
        "\n",
        "def calculate_correlation_matrix(df):\n",
        "    # Calcula la matriz de correlación de Pearson para variables numéricas\n",
        "    corr_matrix = df.corr(method='pearson')\n",
        "    return corr_matrix\n",
        "\n",
        "def calculate_uncertainty_coefficient(df, cat_cols):\n",
        "    # Calcula el coeficiente de incertidumbre para variables categóricas\n",
        "    def uncertainty_coefficient(x, y):\n",
        "        contingency_table = pd.crosstab(x, y)\n",
        "        chi2 = chi2_contingency(contingency_table)[0]\n",
        "        n = contingency_table.sum().sum()\n",
        "        entropy_x = entropy(x.value_counts(normalize=True))\n",
        "        entropy_y = entropy(y.value_counts(normalize=True))\n",
        "        return chi2 / n / (min(entropy_x, entropy_y))\n",
        "\n",
        "    n = len(cat_cols)\n",
        "    uc_matrix = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                uc_matrix[i, j] = 1\n",
        "            else:\n",
        "                uc_matrix[i, j] = uncertainty_coefficient(df[cat_cols[i]], df[cat_cols[j]])\n",
        "    return pd.DataFrame(uc_matrix, index=cat_cols, columns=cat_cols)\n",
        "\n",
        "def plot_associations(df):\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    cat_cols = df.select_dtypes(include=[object, 'category']).columns\n",
        "\n",
        "    if numeric_cols.empty:\n",
        "        raise ValueError(\"No numeric columns found in the dataset.\")\n",
        "    if cat_cols.empty:\n",
        "        raise ValueError(\"No categorical columns found in the dataset.\")\n",
        "\n",
        "    corr_matrix = calculate_correlation_matrix(df[numeric_cols])\n",
        "    uc_matrix = calculate_uncertainty_coefficient(df, cat_cols)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    norm = Normalize(vmin=-1, vmax=1)\n",
        "    cmap = plt.cm.bwr\n",
        "\n",
        "    n = len(df.columns)\n",
        "    ax.set_xlim(0, n)\n",
        "    ax.set_ylim(0, n)\n",
        "\n",
        "    found_values = False\n",
        "\n",
        "    for i, col1 in enumerate(df.columns):\n",
        "        for j, col2 in enumerate(df.columns):\n",
        "            if col1 in numeric_cols and col2 in numeric_cols:\n",
        "                corr_value = corr_matrix.loc[col1, col2]\n",
        "                if not np.isnan(corr_value):\n",
        "                    size = abs(corr_value) * 1000\n",
        "                    color = cmap(norm(corr_value))\n",
        "                    shape = 'o'\n",
        "                    ax.scatter(j, n - i - 1, s=size, c=[color], marker=shape)\n",
        "                    found_values = True\n",
        "            elif col1 in cat_cols and col2 in cat_cols:\n",
        "                uc_value = uc_matrix.loc[col1, col2]\n",
        "                if not np.isnan(uc_value):\n",
        "                    size = uc_value * 1000\n",
        "                    color = cmap(norm(uc_value))\n",
        "                    shape = 's'\n",
        "                    ax.scatter(j, n - i - 1, s=size, c=[color], marker=shape)\n",
        "                    found_values = True\n",
        "\n",
        "    if not found_values:\n",
        "        print(\"No valid associations found to plot.\")\n",
        "        return\n",
        "\n",
        "    ax.set_xticks(range(n))\n",
        "    ax.set_xticklabels(df.columns, rotation=90)\n",
        "    ax.set_yticks(range(n))\n",
        "    ax.set_yticklabels(df.columns[::-1])\n",
        "\n",
        "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
        "    sm.set_array([])\n",
        "    cbar = fig.colorbar(sm, ax=ax)\n",
        "    cbar.set_label('Correlation')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Uso: simulacion de data 'raleo_base_clus_clusteres.csv'\n",
        "data = {\n",
        "    'data_Tcamp': [1, 2, 3, 4, 5],\n",
        "    'data_sumCOD': [2, 3, 4, 5, 6],\n",
        "    'data_sumHRSLB': [3, 4, 5, 6, 7],\n",
        "    'data_GRAD02': ['PRIMARIA COMPLETA', 'SECUNDARIA COMPLETA', 'PRIMARIA INCOMPLETA', 'SECUNDARIA COMPLETA', 'SECUNDARIA INCOMPLETA'],\n",
        "    'data_sum.variedad_total_AC': [5, 6, 7, 8, 9],\n",
        "    'data_sum.variedad_total_CC': [6, 7, 8, 9, 10],\n",
        "    'data_sum.variedad_total_CP': [7, 8, 9, 10, 11],\n",
        "    'data_sum.variedad_total_LS': [8, 9, 10, 11, 12]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "plot_associations(df)"
      ],
      "metadata": {
        "id": "XUxwUpIfm3Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "def calculate_correlation(df):\n",
        "    # Calcula la correlación de Pearson solo para columnas numéricas\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    correlation_matrix = numeric_df.corr(method='pearson')\n",
        "    return correlation_matrix\n",
        "\n",
        "def cramers_v(x, y):\n",
        "    confusion_matrix = pd.crosstab(x, y)\n",
        "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
        "    n = confusion_matrix.sum().sum()\n",
        "    return np.sqrt(chi2 / (n * (min(confusion_matrix.shape) - 1)))\n",
        "\n",
        "def calculate_association(df):\n",
        "    cols = df.columns\n",
        "    association_matrix = pd.DataFrame(index=cols, columns=cols)\n",
        "\n",
        "    for i in range(len(cols)):\n",
        "        for j in range(i, len(cols)):\n",
        "            col1 = df[cols[i]]\n",
        "            col2 = df[cols[j]]\n",
        "\n",
        "            if col1.dtype == 'object' or col2.dtype == 'object':\n",
        "                association_matrix.iat[i, j] = cramers_v(col1, col2)\n",
        "                association_matrix.iat[j, i] = association_matrix.iat[i, j]\n",
        "            else:\n",
        "                association_matrix.iat[i, j] = np.nan\n",
        "                association_matrix.iat[j, i] = np.nan\n",
        "\n",
        "    return association_matrix\n",
        "\n",
        "def plot_association_correlation(df, title, note):\n",
        "    corr = calculate_correlation(df)\n",
        "    assoc = calculate_association(df)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.title(title)\n",
        "\n",
        "    sns.heatmap(corr, annot=False, cmap=\"coolwarm\", center=0, cbar_kws={'label': 'Correlación (Pearson)'}, square=True, linewidths=.5)\n",
        "\n",
        "    for i in range(len(corr.columns)):\n",
        "        for j in range(len(corr.columns)):\n",
        "            if i != j:\n",
        "                size = abs(assoc.iloc[i, j])\n",
        "                if not np.isnan(size):\n",
        "                    plt.gca().add_patch(mpatches.Rectangle((j, i), 1, 1, fill=False, edgecolor='blue', lw=size * 5, linestyle='-', alpha=0.3))\n",
        "\n",
        "    for i in range(len(corr.columns)):\n",
        "        for j in range(len(corr.columns)):\n",
        "            if i != j:\n",
        "                size = abs(corr.iloc[i, j])\n",
        "                if not np.isnan(size):\n",
        "                    plt.gca().add_patch(plt.Circle((j + 0.5, i + 0.5), size / 2, color='blue', alpha=0.3))\n",
        "\n",
        "    plt.xticks(np.arange(len(df.columns)) + 0.5, df.columns, rotation=90)\n",
        "    plt.yticks(np.arange(len(df.columns)) + 0.5, df.columns, rotation=0)\n",
        "    plt.gca().set_xticks(np.arange(len(df.columns)) + 0.5, minor=True)\n",
        "    plt.gca().set_yticks(np.arange(len(df.columns)) + 0.5, minor=True)\n",
        "    plt.gca().grid(False, which='minor', color='black', linestyle='-', linewidth=2)\n",
        "\n",
        "    plt.figtext(0.5, -0.1, note, wrap=True, horizontalalignment='center', fontsize=10, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Título y nota\n",
        "title = \"Asociaciones\"\n",
        "note = (\"Solo incluyendo el conjunto de datos analizado\"\n",
        "        \"■ Los cuadrados son asociaciones categóricas (coeficiente de incertidumbre y razón de correlación) de 0 a 1. \"\n",
        "        \"El coeficiente de incertidumbre es asimétrico, (es decir, los valores de la ETIQUETA DE FILA indican cuánto INFORMAN a cada ETIQUETA en la PARTE SUPERIOR). \"\n",
        "        \"• Los círculos son las correlaciones numéricas simétricas (Pearson) de -1 a 1. La diagonal trivial se deja intencionalmente en blanco para mayor claridad.\")\n",
        "\n",
        "\n",
        "# Gráfica\n",
        "plot_association_correlation(df, title, note)\n"
      ],
      "metadata": {
        "id": "Hl5l3zc2m-Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import matplotlib.patches as patches\n",
        "from textwrap import wrap\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Definiciones globales y configuraciones\n",
        "CORRELATION_ERROR = 83572398457329.0\n",
        "CORRELATION_IDENTICAL = 1357239845732.0\n",
        "\n",
        "def wrap_custom(source_text, separator_chars, width=70, keep_separators=True):\n",
        "    current_length = 0\n",
        "    latest_separator = -1\n",
        "    current_chunk_start = 0\n",
        "    output = \"\"\n",
        "    char_index = 0\n",
        "    while char_index < len(source_text):\n",
        "        if source_text[char_index] in separator_chars:\n",
        "            latest_separator = char_index\n",
        "        output += source_text[char_index]\n",
        "        current_length += 1\n",
        "        if current_length == width:\n",
        "            if latest_separator >= current_chunk_start:\n",
        "                cutting_length = char_index - latest_separator\n",
        "                if not keep_separators:\n",
        "                    cutting_length += 1\n",
        "                if cutting_length:\n",
        "                    output = output[:-cutting_length]\n",
        "                output += \"\\n\"\n",
        "                current_chunk_start = latest_separator + 1\n",
        "                char_index = current_chunk_start\n",
        "            else:\n",
        "                output += \"\\n\"\n",
        "                current_chunk_start = char_index + 1\n",
        "                latest_separator = current_chunk_start - 1\n",
        "                char_index += 1\n",
        "            current_length = 0\n",
        "        else:\n",
        "            char_index += 1\n",
        "    return output\n",
        "\n",
        "def cramers_v(x, y):\n",
        "    confusion_matrix = pd.crosstab(x, y)\n",
        "    if confusion_matrix.shape[0] <= 1 or confusion_matrix.shape[1] <= 1:\n",
        "        return np.nan\n",
        "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
        "    n = confusion_matrix.sum().sum()\n",
        "    return np.sqrt(chi2 / (n * (min(confusion_matrix.shape) - 1)))\n",
        "\n",
        "def make_zero_square_dataframe(features):\n",
        "    new_dataframe = pd.DataFrame()\n",
        "    for feature in features:\n",
        "        new_dataframe[feature] = pd.Series(dtype=float)\n",
        "    return new_dataframe.reindex(list(range(0, len(features)))).reset_index(drop=True).fillna(0.0)\n",
        "\n",
        "def calculate_association(df):\n",
        "    cols = df.columns\n",
        "    association_matrix = pd.DataFrame(index=cols, columns=cols)\n",
        "\n",
        "    for i in range(len(cols)):\n",
        "        for j in range(i, len(cols)):\n",
        "            col1 = df[cols[i]]\n",
        "            col2 = df[cols[j]]\n",
        "\n",
        "            if col1.dtype == 'object' or col2.dtype == 'object':\n",
        "                association_matrix.iat[i, j] = cramers_v(col1, col2)\n",
        "                association_matrix.iat[j, i] = association_matrix.iat[i, j]\n",
        "            else:\n",
        "                association_matrix.iat[i, j] = np.nan\n",
        "                association_matrix.iat[j, i] = np.nan\n",
        "\n",
        "    return association_matrix\n",
        "\n",
        "def calculate_correlation(df):\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    correlation_matrix = numeric_df.corr(method='pearson')\n",
        "    return correlation_matrix\n",
        "\n",
        "def corrplot(correlation_dataframe, dataframe_report, size_scale=100, marker='s'):\n",
        "    corr = pd.melt(correlation_dataframe.reset_index(), id_vars='index')\n",
        "    corr.columns = ['x', 'y', 'value']\n",
        "\n",
        "    def heatmap(y, x, figure_size, **kwargs):\n",
        "        color = kwargs.get('color', [1]*len(x))\n",
        "        palette = [(0.85, (0.85/128)*i, (0.85/128)*i) for i in range(0,128)] + [(0.85 - 0.85*(i-128.0)/128.0, 0.85 - 0.85*(i-128.0)/128.0, 0.85) for i in range(128,256)]\n",
        "        color_min, color_max = kwargs.get('color_range', (min(color), max(color)))\n",
        "\n",
        "        def value_to_color(val):\n",
        "            if color_min == color_max:\n",
        "                return palette[-1]\n",
        "            if val == CORRELATION_IDENTICAL or val == CORRELATION_ERROR:\n",
        "                return palette[-1]\n",
        "            val_position = float((val - color_min)) / (color_max - color_min)\n",
        "            val_position = min(max(val_position, 0), 1)\n",
        "            val_position = math.pow(val_position, 0.925)\n",
        "            ind = int(val_position * 255)\n",
        "            return palette[ind]\n",
        "\n",
        "        size = kwargs.get('size', [1]*len(x))\n",
        "        size_min, size_max = kwargs.get('size_range', (min(size), max(size)))\n",
        "        size_scale = kwargs.get('size_scale', 500) / len(x)\n",
        "\n",
        "        def value_to_size(val):\n",
        "            if val == 0 or val == abs(CORRELATION_IDENTICAL) or val == abs(CORRELATION_ERROR):\n",
        "                return 0.0\n",
        "            if size_min == size_max:\n",
        "                return 1 * size_scale\n",
        "            val_position = (val - size_min) * 0.999 / (size_max - size_min) + 0.001\n",
        "            val_position = min(max(val_position, 0), 1)\n",
        "            val_position = math.pow(val_position, 0.5)\n",
        "            return val_position\n",
        "\n",
        "        def do_wrapping(label, length):\n",
        "            return wrap_custom(label, [\"_\", \"-\"], length)\n",
        "\n",
        "        wrap_x = 12\n",
        "        wrap_y = 13\n",
        "        x_names = [t for t in kwargs.get('x_order', sorted(set([v for v in x])))]\n",
        "        x_names = [do_wrapping(label, wrap_x) for label in x_names]\n",
        "        x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n",
        "\n",
        "        y_names = [t for t in kwargs.get('y_order', sorted(set([v for v in y])))]\n",
        "        y_names = [do_wrapping(label, wrap_y) for label in y_names]\n",
        "        y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n",
        "\n",
        "        figure, axs = plt.subplots(1, 1, figsize=figure_size)\n",
        "\n",
        "        marker = kwargs.get('marker', 's')\n",
        "\n",
        "        kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in ['color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', 'y_order']}\n",
        "\n",
        "        axs.tick_params(labelbottom='on', labeltop='on')\n",
        "        axs.set_xticks([v for k,v in x_to_num.items()])\n",
        "        axs.set_xticklabels([k for k in x_to_num], rotation=90, horizontalalignment='center', linespacing=0.8)\n",
        "        axs.set_yticks([v for k,v in y_to_num.items()])\n",
        "        axs.set_yticklabels([k for k in y_to_num], linespacing=0.85)\n",
        "\n",
        "        axs.grid(False, 'major')\n",
        "        axs.grid(True, 'minor')\n",
        "        axs.set_xticks([t + 0.5 for t in axs.get_xticks()], minor=True)\n",
        "        axs.set_yticks([t + 0.5 for t in axs.get_yticks()], minor=True)\n",
        "\n",
        "        axs.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
        "        axs.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
        "        axs.set_facecolor('#F1F1F1')\n",
        "\n",
        "        delta_in_pix = axs.transData.transform((1, 1)) - axs.transData.transform((0, 0))\n",
        "\n",
        "        index = 0\n",
        "        for cur_x, cur_y in zip(x,y):\n",
        "            wrapped_x_name = do_wrapping(cur_x, wrap_x)\n",
        "            wrapped_y_name = do_wrapping(cur_y, wrap_y)\n",
        "            before_coordinate = np.array(axs.transData.transform((x_to_num[wrapped_x_name]-0.5, y_to_num[wrapped_y_name] -0.5)))\n",
        "            after_coordinate = np.array(axs.transData.transform((x_to_num[wrapped_x_name]+0.5, y_to_num[wrapped_y_name] +0.5)))\n",
        "            before_pixels = np.round(before_coordinate, 0)\n",
        "            after_pixels = np.round(after_coordinate, 0)\n",
        "            desired_fraction = value_to_size(size[index])\n",
        "            if desired_fraction == 0.0:\n",
        "                index += 1\n",
        "                continue\n",
        "            use_rectangle = True if dataframe_report[cur_x][\"type\"] != \"NUM\" or dataframe_report[cur_y][\"type\"] != \"NUM\" else False\n",
        "            delta_in_pix = after_pixels - before_pixels\n",
        "            gap = np.round((1.0 - desired_fraction) * delta_in_pix / 2, 0)\n",
        "            start = before_pixels + gap[0]\n",
        "            ending = after_pixels - gap[0]\n",
        "            start[0] += 1\n",
        "            ending[1] -= 1\n",
        "            start_doc = axs.transData.inverted().transform(start)\n",
        "            ending_doc = axs.transData.inverted().transform(ending)\n",
        "            cur_size = ending_doc - start_doc\n",
        "            if use_rectangle:\n",
        "                                    cur_rect = patches.Rectangle((start_doc[0], start_doc[1]), cur_size[0], cur_size[1], facecolor=value_to_color(color[index]), antialiased=True)\n",
        "            else:\n",
        "                cur_rect = patches.Circle((start_doc[0] + cur_size[0] / 2, start_doc[1] + cur_size[1] / 2), cur_size[0] / 2, facecolor=value_to_color(color[index]), antialiased=True)\n",
        "            cur_rect.set_antialiased(True)\n",
        "            axs.add_patch(cur_rect)\n",
        "            index += 1\n",
        "\n",
        "        if color_min < color_max:\n",
        "            ax = plt.subplot2grid((1, 15), (0, 14))\n",
        "            col_x = [0] * len(palette)\n",
        "            bar_y = np.linspace(color_min, color_max, len(palette))\n",
        "            ax.set_ylim(-1, 1)\n",
        "            bar_height = bar_y[1] - bar_y[0]\n",
        "            ax.barh(\n",
        "                y=bar_y,\n",
        "                width=[5] * len(palette),\n",
        "                left=col_x,\n",
        "                height=bar_height,\n",
        "                color=palette,\n",
        "                linewidth=0)\n",
        "            ax.set_xlim(1, 2)\n",
        "            ax.grid(False)\n",
        "            ax.set_facecolor('white')\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks(np.linspace(min(bar_y), max(bar_y), 3))\n",
        "            ax.yaxis.tick_right()\n",
        "        return figure\n",
        "\n",
        "    return heatmap(\n",
        "        corr['y'], corr['x'],\n",
        "        figure_size=(20, 15),\n",
        "        color=corr['value'], color_range=[-1, 1],\n",
        "        size=corr['value'].abs(), size_range=[0, 1],\n",
        "        marker=marker,\n",
        "        x_order=correlation_dataframe.columns,\n",
        "        y_order=correlation_dataframe.columns[::-1],\n",
        "        size_scale=size_scale,\n",
        "        dataframe_report=dataframe_report\n",
        "    )\n",
        "\n",
        "def create_dataframe_report(df):\n",
        "    dataframe_report = {}\n",
        "    for col in df.columns:\n",
        "        col_type = 'NUM' if pd.api.types.is_numeric_dtype(df[col]) else 'CAT'\n",
        "        dataframe_report[col] = {\"type\": col_type}\n",
        "    return dataframe_report\n",
        "\n",
        "def plot_association_correlation(df, title, note):\n",
        "    # Crear el reporte del dataframe\n",
        "    dataframe_report = create_dataframe_report(df)\n",
        "\n",
        "    # Calcular correlaciones y asociaciones\n",
        "    corr = calculate_correlation(df)\n",
        "    assoc = calculate_association(df)\n",
        "\n",
        "    # Crear un dataframe combinado para la visualización\n",
        "    combined = corr.copy()\n",
        "    for col in assoc.columns:\n",
        "        if col not in combined.columns:\n",
        "            combined[col] = np.nan\n",
        "    for index, row in assoc.iterrows():\n",
        "        for col in assoc.columns:\n",
        "            combined.at[index, col] = assoc.at[index, col]\n",
        "\n",
        "    # Generar la gráfica\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    plt.title(title)\n",
        "\n",
        "    corrplot(combined, dataframe_report, size_scale=100, marker='s')\n",
        "\n",
        "    # Añadir la nota\n",
        "    plt.figtext(0.5, -0.1, note, wrap=True, horizontalalignment='center', fontsize=12, bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Nota y título\n",
        "title = \"Asociaciones\"\n",
        "note = (\"Solo incluyendo el conjunto de datos analizado\"\n",
        "        \"■ Los cuadrados son asociaciones categóricas (coeficiente de incertidumbre y razón de correlación) de 0 a 1. \"\n",
        "        \"El coeficiente de incertidumbre es asimétrico, (es decir, los valores de la ETIQUETA DE FILA indican cuánto INFORMAN a cada ETIQUETA en la PARTE SUPERIOR). \"\n",
        "        \"• Los círculos son las correlaciones numéricas simétricas (Pearson) de -1 a 1. La diagonal trivial se deja intencionalmente en blanco para mayor claridad.\")\n",
        "\n",
        "# Gráfica\n",
        "plot_association_correlation(df, title, note)"
      ],
      "metadata": {
        "id": "3DwYJrK_nDb5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}